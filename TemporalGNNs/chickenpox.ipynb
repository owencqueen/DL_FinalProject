{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uG7eLbcsw5u"
   },
   "source": [
    "# Static Graph Predictions\n",
    "\n",
    "> Indented block\n",
    "\n",
    "\n",
    "Mostly copied from: https://github.com/mims-harvard/graphml-tutorials/blob/master/01-intro/gnn-intro.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xITbaAVCss6j"
   },
   "outputs": [],
   "source": [
    "#import sys; sys.path.insert(0, '/content/drive/Shareddrives/DL_525/pgeo_packages')\n",
    "# Above line links in the packages needed to run Pytorch Geometric\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.data import DataLoader, Dataset\n",
    "from torch_geometric.datasets import Planetoid, Entities\n",
    "from torch_geometric.nn import GCNConv, RGCNConv, GATConv, SAGEConv, JumpingKnowledge, GINConv, DeepGraphInfomax, global_mean_pool\n",
    "from torch_geometric.utils.convert import from_networkx, to_networkx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# To load in the data from pickles:\n",
    "import pickle, os\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oILq8h2ntNGR"
   },
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "\n",
    "loader = ChickenpoxDatasetLoader()\n",
    "\n",
    "# Time lag - how many weeks to look back\n",
    "node_features = 8\n",
    "filter_size = 4\n",
    "dataset = loader.get_dataset(node_features)\n",
    "\n",
    "train_dataset, test_dataset = temporal_signal_split(dataset, train_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4d-OcHypP-fz"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "\n",
    "class RecurrentGCN(torch.nn.Module):\n",
    "  def __init__(self, node_features):\n",
    "      super(RecurrentGCN, self).__init__()\n",
    "      self.recurrent = DCRNN(node_features, 32, filter_size)\n",
    "      self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "      h = self.recurrent(x, edge_index, edge_weight)\n",
    "      h = F.relu(h)\n",
    "      h = self.linear(h)\n",
    "      return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN2(torch.nn.Module):\n",
    "  def __init__(self, node_features):\n",
    "      super(RecurrentGCN2, self).__init__()\n",
    "      self.recurrent = DCRNN(node_features, 32, filter_size)\n",
    "      self.recurrent2 = DCRNN(32, 32, 1)\n",
    "      self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "      h = self.recurrent(x, edge_index, edge_weight)\n",
    "      h = F.relu(h)\n",
    "      h = self.recurrent2(h, edge_index, edge_weight)\n",
    "      h = F.relu(h)\n",
    "      h = self.linear(h)\n",
    "      return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN3(torch.nn.Module):\n",
    "  def __init__(self, node_features):\n",
    "      super(RecurrentGCN3, self).__init__()\n",
    "      self.recurrent = DCRNN(node_features, 32, filter_size)\n",
    "      self.recurrent2 = DCRNN(32, 32, 1)\n",
    "      self.recurrent3 = DCRNN(32, 32, 1)\n",
    "      self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "      h = self.recurrent(x, edge_index, edge_weight)\n",
    "      h = F.relu(h)\n",
    "      h = self.recurrent2(h, edge_index, edge_weight)\n",
    "      h = F.relu(h)\n",
    "      h = self.recurrent3(h, edge_index, edge_weight)\n",
    "      h = F.relu(h)\n",
    "      h = self.linear(h)\n",
    "      return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TvKyF6ztEs6j"
   },
   "outputs": [],
   "source": [
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "\n",
    "class GCGRU(torch.nn.Module):\n",
    "  def __init__(self, node_features):\n",
    "    super(GCGRU, self).__init__()\n",
    "    self.recurrent = GConvGRU(node_features, 32, filter_size)\n",
    "    self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "    h = self.recurrent(x, edge_index, edge_weight)\n",
    "    h = F.relu(h)\n",
    "    h = self.linear(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCGRU2(torch.nn.Module):\n",
    "  def __init__(self, node_features):\n",
    "    super(GCGRU2, self).__init__()\n",
    "    self.recurrent1 = GConvGRU(node_features, 32, filter_size)\n",
    "    self.recurrent2 = GConvGRU(32, 32, 1)\n",
    "    self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "    h = self.recurrent1(x, edge_index, edge_weight)\n",
    "    h = F.relu(h)\n",
    "    h = self.recurrent2(h, edge_index, edge_weight)\n",
    "    h = F.relu(h)\n",
    "    h = self.linear(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCGRU3(torch.nn.Module):\n",
    "  def __init__(self, node_features):\n",
    "    super(GCGRU3, self).__init__()\n",
    "    self.recurrent1 = GConvGRU(node_features, 32, filter_size)\n",
    "    self.recurrent2 = GConvGRU(32, 32, 1)\n",
    "    self.recurrent3 = GConvGRU(32, 32, 1)\n",
    "    self.linear = torch.nn.Linear(32, 1)\n",
    "\n",
    "  def forward(self, x, edge_index, edge_weight):\n",
    "    h = self.recurrent1(x, edge_index, edge_weight)\n",
    "    h = F.relu(h)\n",
    "    h = self.recurrent2(h, edge_index, edge_weight)\n",
    "    h = F.relu(h)\n",
    "    h = self.recurrent3(h, edge_index, edge_weight)\n",
    "    h = F.relu(h)\n",
    "    h = self.linear(h)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSEloss(y_hat, y):\n",
    "  return torch.mean((y_hat-y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, test_dataset):\n",
    "  \"\"\"\n",
    "  loop for evaluating dataset passed\n",
    "  \n",
    "  Args:\n",
    "    model (Pytorch model): model\n",
    "    test_dataset (Iterator): dataset iterator\n",
    "    \n",
    "  Returns:\n",
    "    r2 (float): average R2 accuracy over dataset\n",
    "    cost (float): average MSE loss over dataset\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  cost = 0\n",
    "  r2 = 0\n",
    "  for time, snapshot in enumerate(test_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    cost = cost + torch.mean((y_hat-snapshot.y)**2)\n",
    "    y = snapshot.y\n",
    "    r2 += r2_score(y.detach().numpy(), y_hat.cpu().detach().numpy())\n",
    "  r2 = r2 / (time+1)\n",
    "  cost = cost / (time+1)\n",
    "  return r2, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, epochs, train_dataset, test_dataset, optimizer):\n",
    "  \"\"\"\n",
    "    loop for training\n",
    "    \n",
    "    Args:\n",
    "        model (pytorch model): model\n",
    "        epochs (int): number of epochs\n",
    "        train_dataset (Iterator): PyG data iterator\n",
    "        test_dataset (Iterator): PyG data iterator\n",
    "        optimizer (torch optimizer): Pytorch model optimizer\n",
    "    Returns:\n",
    "        train_loss (list): train loss values\n",
    "        test_loss (list): test loss values\n",
    "        train_acc (list): train accuracy values\n",
    "        test_acc (list): test accuracy values\n",
    "  \"\"\"\n",
    "  model.train()\n",
    "  train_loss = []\n",
    "  test_loss = []\n",
    "  train_acc = []\n",
    "  test_acc = []\n",
    "\n",
    "  for epoch in tqdm(range(epochs)):\n",
    "    cost = 0\n",
    "    for time, snapshot in enumerate(train_dataset):\n",
    "      y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "      mse = MSEloss(y_hat, snapshot.y)\n",
    "      cost = cost + mse\n",
    "    cost = cost / (time+1)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_loss.append(cost)\n",
    "    te_acc, te_loss = test_eval(model, test_dataset) # Get accuracy after the epoch\n",
    "    tr_acc, tr_loss = test_eval(model, train_dataset)\n",
    "    \n",
    "    train_acc.append(tr_acc)\n",
    "    test_acc.append(te_acc)\n",
    "    test_loss.append(te_loss)\n",
    "  \n",
    "  return train_loss, test_loss, train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(model, epochs, train_dataset, test_dataset, optimizer, ml_name=\"blah\"):\n",
    "    \"\"\"\n",
    "    Controller for training, evaluation at each time step, and plotting loss and accuracy curves\n",
    "    \n",
    "    Args:\n",
    "        model (pytorch model): model\n",
    "        epochs (int): number of epochs\n",
    "        train_dataset (Iterator): PyG data iterator\n",
    "        test_dataset (Iterator): PyG data iterator\n",
    "        optimizer (torch optimizer): Pytorch model optimizer\n",
    "        ml_name (str, optional): name for plots and saving CSVs and PNGs\n",
    "    \"\"\"\n",
    "    tr_loss, te_loss, tr_acc, te_acc = train_loop(model, epochs, train_dataset, test_dataset, optimizer)\n",
    "    x = list(range(len(tr_loss)))\n",
    "    xt = list(range(len(te_loss)))\n",
    "\n",
    "    results = pd.DataFrame({'Train_Acc':tr_acc, 'Test_Acc':te_acc, 'Train_Loss':[i.detach().numpy() for i in tr_loss], 'Test_Loss': te_loss})\n",
    "    results['model'] = [ml_name] + [None] * (len(tr_loss) - 1)\n",
    "    results.to_csv(ml_name+'.csv', index = False)\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(x, tr_acc, label = 'Train R^2')\n",
    "    ax1.plot(x, te_acc, label = 'Test R^2')\n",
    "    r2_title = 'Coef. of Determination Scores '+ml_name\n",
    "    ax1.set_title(r2_title)\n",
    "    ax1.legend()\n",
    "    fig.savefig(ml_name+'_r2.png')\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig, ax2 = plt.subplots()\n",
    "    ax2.plot(xt, tr_loss, label = 'Train MSE loss')\n",
    "    ax2.plot(xt, te_loss, label = 'Test MSE loss')\n",
    "    mse_title = 'MSE loss '+ml_name\n",
    "    ax2.set_title(mse_title)\n",
    "    ax2.legend()\n",
    "    fig.savefig(ml_name+'_loss.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:24<00:00,  3.12s/it]\n"
     ]
    }
   ],
   "source": [
    "model = RecurrentGCN(node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "plot(model, 200, train_dataset, test_dataset, optimizer, 'dcrnn_1_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [13:22<00:00,  4.01s/it]\n"
     ]
    }
   ],
   "source": [
    "model = RecurrentGCN2(node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "plot(model, 200, train_dataset, test_dataset, optimizer, 'dcrnn_2_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [13:53<00:00,  4.91s/it]\n"
     ]
    }
   ],
   "source": [
    "model = RecurrentGCN3(node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "plot(model, 170, train_dataset, test_dataset, optimizer, 'dcrnn_3_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [12:08<00:00,  3.64s/it]\n"
     ]
    }
   ],
   "source": [
    "model = GCGRU(node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "plot(model, 200, train_dataset, test_dataset, optimizer, 'gcgru_1_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [16:31<00:00,  5.08s/it]\n"
     ]
    }
   ],
   "source": [
    "model = GCGRU2(node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "plot(model, 195, train_dataset, test_dataset, optimizer, 'gcgru_2_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [17:09<00:00,  6.86s/it]\n"
     ]
    }
   ],
   "source": [
    "model = GCGRU3(node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "plot(model, 150, train_dataset, test_dataset, optimizer, 'gcgru_3_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKiPqaA4t9-3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3nl6KXZQW3ac"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "chickenpox.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "pytorch-gpu.1-8.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-8:m65"
  },
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
